{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "application_train = pd.read_csv('/home/sidharthjindal/HV/home-credit-default-risk/application_train.csv')\n",
    "pos_cash= pd.read_csv('/home/sidharthjindal/HV/home-credit-default-risk/POS_CASH_balance.csv')\n",
    "bureau_balance = pd.read_csv('/home/sidharthjindal/HV/home-credit-default-risk/bureau_balance.csv')\n",
    "previous_application = pd.read_csv('/home/sidharthjindal/HV/home-credit-default-risk/previous_application.csv')\n",
    "install_payments = pd.read_csv('/home/sidharthjindal/HV/home-credit-default-risk/installments_payments.csv')\n",
    "credit_card = pd.read_csv('/home/sidharthjindal/HV/home-credit-default-risk/credit_card_balance.csv')\n",
    "bureau = pd.read_csv('/home/sidharthjindal/HV/home-credit-default-risk/bureau.csv')\n",
    "application_test = pd.read_csv('/home/sidharthjindal/HV/home-credit-default-risk/application_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these categorical variables hold binary data, so could be converted to 1 ,0\n",
    "application_train = application_train[application_train['CODE_GENDER'].notna()]\n",
    "col_for_dummies=application_train.select_dtypes(include=['O']).columns.drop(['CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','EMERGENCYSTATE_MODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_dummies = pd.get_dummies(application_train, columns = col_for_dummies, drop_first = True)\n",
    "application_test_dummies = pd.get_dummies(application_test, columns = col_for_dummies, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_dummies['CODE_GENDER'] = application_train_dummies['CODE_GENDER'].map( {'F':1, 'M':0})\n",
    "application_train_dummies['FLAG_OWN_CAR'] = application_train_dummies['FLAG_OWN_CAR'].map( {'Y':1, 'N':0})\n",
    "application_train_dummies['FLAG_OWN_REALTY'] = application_train_dummies['FLAG_OWN_REALTY'].map( {'Y':1, 'N':0})\n",
    "application_train_dummies['EMERGENCYSTATE_MODE'] = application_train_dummies['EMERGENCYSTATE_MODE'].map( {'Yes':1, 'No':0})\n",
    "\n",
    "application_test_dummies['CODE_GENDER'] = application_test_dummies['CODE_GENDER'].map({'F':1, 'M':0})\n",
    "application_test_dummies['FLAG_OWN_CAR'] = application_test_dummies['FLAG_OWN_CAR'].map( {'Y':1, 'N':0})\n",
    "application_test_dummies['FLAG_OWN_REALTY'] = application_test_dummies['FLAG_OWN_REALTY'].map( {'Y':1, 'N':0})\n",
    "application_test_dummies['EMERGENCYSTATE_MODE'] = application_test_dummies['EMERGENCYSTATE_MODE'].map( {'Yes':1, 'No':0})\n",
    "\n",
    "\n",
    "train_labels = application_train_dummies['TARGET']\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "application_train_dummies, application_test_dummies = application_train_dummies.align(application_test_dummies, join = 'inner', axis = 1)\n",
    "# Add the target back in\n",
    "application_train_dummies['TARGET'] = train_labels\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_dummies['Percent_Days_employed'] = application_train_dummies['DAYS_EMPLOYED']/application_train_dummies['DAYS_BIRTH']*100\n",
    "application_train_dummies['Credit_as_percent_income'] = application_train_dummies['AMT_CREDIT']/application_train_dummies['AMT_INCOME_TOTAL']*100\n",
    "application_train_dummies['Credit_flag'] = application_train_dummies['AMT_INCOME_TOTAL'] > application_train_dummies['AMT_CREDIT']\n",
    "application_train_dummies['Annuity_as_percent_income'] = application_train_dummies['AMT_ANNUITY']/ application_train_dummies['AMT_INCOME_TOTAL']*100\n",
    "application_train_dummies['Credit_to_annuity'] = application_train_dummies['AMT_CREDIT']/ application_train_dummies['AMT_ANNUITY']\n",
    "application_train_dummies['Credit_to_Goods'] = application_train_dummies['AMT_CREDIT']/ application_train_dummies['AMT_GOODS_PRICE']\n",
    "\n",
    "\n",
    "application_test_dummies['Percent_Days_employed'] = application_test_dummies['DAYS_EMPLOYED']/application_test_dummies['DAYS_BIRTH']*100\n",
    "application_test_dummies['Credit_as_percent_income'] = application_test_dummies['AMT_CREDIT']/application_test_dummies['AMT_INCOME_TOTAL']*100\n",
    "application_test_dummies['Credit_flag'] = application_test_dummies['AMT_INCOME_TOTAL'] > application_test_dummies['AMT_CREDIT']\n",
    "application_test_dummies['Annuity_as_percent_income'] = application_test_dummies['AMT_ANNUITY']/ application_test_dummies['AMT_INCOME_TOTAL']*100\n",
    "application_test_dummies['Credit_to_annuity'] = application_test_dummies['AMT_CREDIT']/ application_test_dummies['AMT_ANNUITY']\n",
    "application_test_dummies['Credit_to_Goods'] = application_test_dummies['AMT_CREDIT']/ application_test_dummies['AMT_GOODS_PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = bureau.drop(['SK_ID_BUREAU'], axis = 1).groupby(by=['SK_ID_CURR']).mean().reset_index()\n",
    "grp.columns = ['BUREAU_'+column if column !='SK_ID_CURR' else column for column in grp.columns]\n",
    "\n",
    "application_bureau = application_train_dummies.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau.update(application_bureau[grp.columns].fillna(0))\n",
    "\n",
    "application_bureau_test = application_test_dummies.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test.update(application_bureau_test[grp.columns].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max days since credit ended\n",
    "grp = bureau.drop(['SK_ID_BUREAU'], axis = 1).groupby(by=['SK_ID_CURR'])['DAYS_ENDDATE_FACT'].max().reset_index().rename(columns = {'DAYS_ENDDATE_FACT': 'DAYS_ENDDATE_FACT_MAX'})\n",
    "\n",
    "application_bureau = application_bureau.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau.update(application_bureau['DAYS_ENDDATE_FACT_MAX'].fillna(0))\n",
    "\n",
    "application_bureau_test = application_bureau_test.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test.update(application_bureau_test['DAYS_ENDDATE_FACT_MAX'].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAX_Annuity_Approved to Current_Annuity Ratio\n",
    "grp = bureau.drop(['SK_ID_BUREAU'], axis = 1).groupby(by=['SK_ID_CURR'])['AMT_ANNUITY'].max().reset_index().rename(columns = {'AMT_ANNUITY': 'AMT_ANNUITY_MAX'})\n",
    "\n",
    "grp2 = application_bureau[['SK_ID_CURR','AMT_ANNUITY']]\n",
    "grp2 = grp2.merge(grp, on = 'SK_ID_CURR', how = 'left')\n",
    "grp2.update(grp2['AMT_ANNUITY_MAX'].fillna(0))\n",
    "grp2['CURRENT_ANNUITY_TO_AMT_ANNUITY_MAX'] = grp2['AMT_ANNUITY']/grp2['AMT_ANNUITY_MAX']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del(grp2['AMT_ANNUITY'])\n",
    "del(grp2['AMT_ANNUITY_MAX'])\n",
    "application_bureau = application_bureau.merge(grp2, on='SK_ID_CURR', how='left')\n",
    "application_bureau.update(application_bureau['CURRENT_ANNUITY_TO_AMT_ANNUITY_MAX'].fillna(0))\n",
    "\n",
    "grp2 = application_bureau_test[['SK_ID_CURR','AMT_ANNUITY']]\n",
    "grp2 = grp2.merge(grp, on = 'SK_ID_CURR', how = 'left')\n",
    "grp2.update(grp2['AMT_ANNUITY_MAX'].fillna(0))\n",
    "grp2['CURRENT_ANNUITY_TO_AMT_ANNUITY_MAX'] = grp2['AMT_ANNUITY']/grp2['AMT_ANNUITY_MAX']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del(grp2['AMT_ANNUITY'])\n",
    "del(grp2['AMT_ANNUITY_MAX'])\n",
    "application_bureau_test = application_bureau_test.merge(grp2, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test.update(application_bureau_test['CURRENT_ANNUITY_TO_AMT_ANNUITY_MAX'].fillna(0))\n",
    "\n",
    "\n",
    "\n",
    "#Mean_Annuity_Approved to Current_Annuity Ratio\n",
    "grp = bureau.drop(['SK_ID_BUREAU'], axis = 1).groupby(by=['SK_ID_CURR'])['AMT_ANNUITY'].mean().reset_index().rename(columns = {'AMT_ANNUITY': 'AMT_ANNUITY_MEAN'})\n",
    "\n",
    "grp2 = application_bureau[['SK_ID_CURR','AMT_ANNUITY']]\n",
    "grp2 = grp2.merge(grp, on = 'SK_ID_CURR', how = 'left')\n",
    "grp2.update(grp2['AMT_ANNUITY_MEAN'].fillna(0))\n",
    "grp2['CURRENT_ANNUITY_TO_AMT_ANNUITY_MEAN'] = grp2['AMT_ANNUITY']/grp2['AMT_ANNUITY_MEAN']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del(grp2['AMT_ANNUITY'])\n",
    "del(grp2['AMT_ANNUITY_MEAN'])\n",
    "application_bureau = application_bureau.merge(grp2, on='SK_ID_CURR', how='left')\n",
    "application_bureau.update(application_bureau['CURRENT_ANNUITY_TO_AMT_ANNUITY_MEAN'].fillna(0))\n",
    "\n",
    "grp2 = application_bureau_test[['SK_ID_CURR','AMT_ANNUITY']]\n",
    "grp2 = grp2.merge(grp, on = 'SK_ID_CURR', how = 'left')\n",
    "grp2.update(grp2['AMT_ANNUITY_MEAN'].fillna(0))\n",
    "grp2['CURRENT_ANNUITY_TO_AMT_ANNUITY_MEAN'] = grp2['AMT_ANNUITY']/grp2['AMT_ANNUITY_MEAN']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del(grp2['AMT_ANNUITY'])\n",
    "del(grp2['AMT_ANNUITY_MEAN'])\n",
    "application_bureau_test = application_bureau_test.merge(grp2, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test.update(application_bureau_test['CURRENT_ANNUITY_TO_AMT_ANNUITY_MEAN'].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratio of credit requested to max credit repaid previous time\n",
    "grp = bureau[bureau['CREDIT_ACTIVE']==\"Closed\"].groupby(by = ['SK_ID_CURR'])['AMT_CREDIT_SUM'].max().reset_index().rename(columns = {'AMT_CREDIT_SUM': 'AMT_CREDIT_SUM_MAX_CLOSED'})\n",
    "\n",
    "grp2 = application_bureau[['SK_ID_CURR','AMT_CREDIT']]\n",
    "grp2 = grp2.merge(grp,on='SK_ID_CURR',how='left')\n",
    "grp2 = grp2.fillna(0)\n",
    "grp2['AmountCredit_OVER_MaxAmountCredited_Closed'] = grp2['AMT_CREDIT']/grp2['AMT_CREDIT_SUM_MAX_CLOSED']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del grp2['AMT_CREDIT']\n",
    "del grp2['AMT_CREDIT_SUM_MAX_CLOSED']\n",
    "application_bureau = application_bureau.merge(grp2, on='SK_ID_CURR', how='left')\n",
    "\n",
    "\n",
    "grp2 = application_bureau_test[['SK_ID_CURR','AMT_CREDIT']]\n",
    "grp2 = grp2.merge(grp,on='SK_ID_CURR',how='left')\n",
    "grp2 = grp2.fillna(0)\n",
    "grp2['AmountCredit_OVER_MaxAmountCredited_Closed'] = grp2['AMT_CREDIT']/grp2['AMT_CREDIT_SUM_MAX_CLOSED']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del grp2['AMT_CREDIT']\n",
    "del grp2['AMT_CREDIT_SUM_MAX_CLOSED']\n",
    "application_bureau_test = application_bureau_test.merge(grp2, on='SK_ID_CURR', how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grp = bureau[bureau['CREDIT_ACTIVE']==\"Active\"].groupby(by = ['SK_ID_CURR'])['AMT_CREDIT_SUM'].max().reset_index().rename(columns = {'AMT_CREDIT_SUM': 'AMT_CREDIT_SUM_MAX_ACTIVE'})\n",
    "\n",
    "grp2 = application_bureau[['SK_ID_CURR','AMT_CREDIT']]\n",
    "grp2 = grp2.merge(grp,on='SK_ID_CURR',how='left')\n",
    "grp2 = grp2.fillna(0)\n",
    "grp2['AmountCredit_OVER_MaxAmountCredited_Active'] = grp2['AMT_CREDIT']/grp2['AMT_CREDIT_SUM_MAX_ACTIVE']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del grp2['AMT_CREDIT']\n",
    "del grp2['AMT_CREDIT_SUM_MAX_ACTIVE']\n",
    "application_bureau = application_bureau.merge(grp2, on='SK_ID_CURR', how='left')\n",
    "\n",
    "\n",
    "grp2 = application_bureau_test[['SK_ID_CURR','AMT_CREDIT']]\n",
    "grp2 = grp2.merge(grp,on='SK_ID_CURR',how='left')\n",
    "grp2 = grp2.fillna(0)\n",
    "grp2['AmountCredit_OVER_MaxAmountCredited_Active'] = grp2['AMT_CREDIT']/grp2['AMT_CREDIT_SUM_MAX_ACTIVE']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del grp2['AMT_CREDIT']\n",
    "del grp2['AMT_CREDIT_SUM_MAX_ACTIVE']\n",
    "application_bureau_test = application_bureau_test.merge(grp2, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Credit(Sum) to Income ratio\n",
    "grp = bureau[bureau['CREDIT_ACTIVE']==\"Active\"].groupby(by = ['SK_ID_CURR'])['AMT_CREDIT_SUM'].sum().reset_index().rename(columns = {'AMT_CREDIT_SUM': 'AMT_CREDIT_SUM_SUM'})\n",
    "\n",
    "grp2 = application_bureau[['SK_ID_CURR','AMT_INCOME_TOTAL']]\n",
    "grp2 = grp2.merge(grp,on='SK_ID_CURR',how='left')\n",
    "grp2 = grp2.fillna(0)\n",
    "grp2['Active_Credit_to_Income_Ratio'] = grp2['AMT_CREDIT_SUM_SUM']/grp2['AMT_INCOME_TOTAL']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del grp2['AMT_INCOME_TOTAL']\n",
    "del grp2['AMT_CREDIT_SUM_SUM']\n",
    "application_bureau = application_bureau.merge(grp2, on='SK_ID_CURR', how='left')\n",
    "\n",
    "\n",
    "grp2 = application_bureau_test[['SK_ID_CURR','AMT_INCOME_TOTAL']]\n",
    "grp2 = grp2.merge(grp,on='SK_ID_CURR',how='left')\n",
    "grp2 = grp2.fillna(0)\n",
    "grp2['Active_Credit_to_Income_Ratio'] = grp2['AMT_CREDIT_SUM_SUM']/grp2['AMT_INCOME_TOTAL']\n",
    "grp2 = grp2.replace([np.inf, -np.inf], 0)\n",
    "del grp2['AMT_INCOME_TOTAL']\n",
    "del grp2['AMT_CREDIT_SUM_SUM']\n",
    "application_bureau_test = application_bureau_test.merge(grp2, on='SK_ID_CURR', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining categorical features\n",
    "bureau_categorical = pd.get_dummies(bureau.select_dtypes('object'))\n",
    "bureau_categorical['SK_ID_CURR'] = bureau['SK_ID_CURR']\n",
    "\n",
    "grp = bureau_categorical.groupby(by = ['SK_ID_CURR']).mean().reset_index()\n",
    "grp.columns = ['BUREAU_'+column if column !='SK_ID_CURR' else column for column in grp.columns]\n",
    "\n",
    "application_bureau = application_bureau.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau.update(application_bureau[grp.columns].fillna(0))\n",
    "\n",
    "application_bureau_test = application_bureau_test.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test.update(application_bureau_test[grp.columns].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of past loans per customer\n",
    "grp = bureau[bureau['CREDIT_ACTIVE']==\"Closed\"].groupby(by = ['SK_ID_CURR'])['SK_ID_BUREAU'].count().reset_index().rename(columns = {'SK_ID_BUREAU': 'BUREAU_LOAN_COUNT_CLOSED'})\n",
    "\n",
    "application_bureau = application_bureau.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau['BUREAU_LOAN_COUNT_CLOSED'] = application_bureau['BUREAU_LOAN_COUNT_CLOSED'].fillna(0)\n",
    "\n",
    "application_bureau_test = application_bureau_test.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test['BUREAU_LOAN_COUNT_CLOSED'] = application_bureau_test['BUREAU_LOAN_COUNT_CLOSED'].fillna(0)\n",
    "\n",
    "\n",
    "grp = bureau[bureau['CREDIT_ACTIVE']==\"Active\"].groupby(by = ['SK_ID_CURR'])['SK_ID_BUREAU'].count().reset_index().rename(columns = {'SK_ID_BUREAU': 'BUREAU_LOAN_COUNT_ACTIVE'})\n",
    "\n",
    "application_bureau = application_bureau.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau['BUREAU_LOAN_COUNT_ACTIVE'] = application_bureau['BUREAU_LOAN_COUNT_ACTIVE'].fillna(0)\n",
    "\n",
    "application_bureau_test = application_bureau_test.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test['BUREAU_LOAN_COUNT_ACTIVE'] = application_bureau_test['BUREAU_LOAN_COUNT_ACTIVE'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of types of past loans per customer \n",
    "grp = bureau[['SK_ID_CURR', 'CREDIT_TYPE']].groupby(by = ['SK_ID_CURR'])['CREDIT_TYPE'].nunique().reset_index().rename(columns={'CREDIT_TYPE': 'BUREAU_LOAN_TYPES'})\n",
    "\n",
    "application_bureau = application_bureau.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau['BUREAU_LOAN_TYPES'] = application_bureau['BUREAU_LOAN_TYPES'].fillna(0)\n",
    "\n",
    "application_bureau_test = application_bureau_test.merge(grp, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test['BUREAU_LOAN_TYPES'] = application_bureau_test['BUREAU_LOAN_TYPES'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debt over credit ratio \n",
    "bureau['AMT_CREDIT_SUM'] = bureau['AMT_CREDIT_SUM'].fillna(0)\n",
    "bureau['AMT_CREDIT_SUM_DEBT'] = bureau['AMT_CREDIT_SUM_DEBT'].fillna(0)\n",
    "\n",
    "grp1 = bureau[['SK_ID_CURR','AMT_CREDIT_SUM']].groupby(by=['SK_ID_CURR'])['AMT_CREDIT_SUM'].sum().reset_index().rename(columns={'AMT_CREDIT_SUM': 'TOTAL_CREDIT_SUM'})\n",
    "\n",
    "grp2 = bureau[['SK_ID_CURR','AMT_CREDIT_SUM_DEBT']].groupby(by=['SK_ID_CURR'])['AMT_CREDIT_SUM_DEBT'].sum().reset_index().rename(columns={'AMT_CREDIT_SUM_DEBT':'TOTAL_CREDIT_SUM_DEBT'})\n",
    "\n",
    "grp1['DEBT_CREDIT_RATIO'] = grp2['TOTAL_CREDIT_SUM_DEBT']/grp1['TOTAL_CREDIT_SUM']\n",
    "\n",
    "del grp1['TOTAL_CREDIT_SUM']\n",
    "\n",
    "application_bureau = application_bureau.merge(grp1, on='SK_ID_CURR', how='left')\n",
    "application_bureau['DEBT_CREDIT_RATIO'].head()\n",
    "application_bureau['DEBT_CREDIT_RATIO'] = application_bureau['DEBT_CREDIT_RATIO'].fillna(0)\n",
    "application_bureau['DEBT_CREDIT_RATIO'] = application_bureau.replace([np.inf, -np.inf], 0)\n",
    "application_bureau['DEBT_CREDIT_RATIO'] = pd.to_numeric(application_bureau['DEBT_CREDIT_RATIO'], downcast='float')\n",
    "\n",
    "application_bureau_test = application_bureau_test.merge(grp1, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test['DEBT_CREDIT_RATIO'] = application_bureau_test['DEBT_CREDIT_RATIO'].fillna(0)\n",
    "application_bureau_test['DEBT_CREDIT_RATIO'] = application_bureau_test.replace([np.inf, -np.inf], 0)\n",
    "application_bureau_test['DEBT_CREDIT_RATIO'] = pd.to_numeric(application_bureau_test['DEBT_CREDIT_RATIO'], downcast='float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overdue over debt ratio\n",
    "bureau['AMT_CREDIT_SUM_OVERDUE'] = bureau['AMT_CREDIT_SUM_OVERDUE'].fillna(0)\n",
    "bureau['AMT_CREDIT_SUM_DEBT'] = bureau['AMT_CREDIT_SUM_DEBT'].fillna(0)\n",
    "\n",
    "grp1 = bureau[['SK_ID_CURR','AMT_CREDIT_SUM_OVERDUE']].groupby(by=['SK_ID_CURR'])['AMT_CREDIT_SUM_OVERDUE'].sum().reset_index().rename(columns={'AMT_CREDIT_SUM_OVERDUE': 'TOTAL_CUSTOMER_OVERDUE'})\n",
    "\n",
    "grp2 = bureau[['SK_ID_CURR','AMT_CREDIT_SUM_DEBT']].groupby(by=['SK_ID_CURR'])['AMT_CREDIT_SUM_DEBT'].sum().reset_index().rename(columns={'AMT_CREDIT_SUM_DEBT':'TOTAL_CUSTOMER_DEBT'})\n",
    "\n",
    "grp1['OVERDUE_DEBT_RATIO'] = grp1['TOTAL_CUSTOMER_OVERDUE']/grp2['TOTAL_CUSTOMER_DEBT']\n",
    "\n",
    "\n",
    "del grp1['TOTAL_CUSTOMER_OVERDUE']\n",
    "\n",
    "application_bureau = application_bureau.merge(grp1, on='SK_ID_CURR', how='left')\n",
    "application_bureau['OVERDUE_DEBT_RATIO'] = application_bureau['OVERDUE_DEBT_RATIO'].fillna(0)\n",
    "application_bureau['OVERDUE_DEBT_RATIO'] = application_bureau.replace([np.inf, -np.inf], 0)\n",
    "application_bureau['OVERDUE_DEBT_RATIO'] = pd.to_numeric(application_bureau['OVERDUE_DEBT_RATIO'], downcast='float')\n",
    "\n",
    "application_bureau_test = application_bureau_test.merge(grp1, on='SK_ID_CURR', how='left')\n",
    "application_bureau_test['OVERDUE_DEBT_RATIO'] = application_bureau_test['OVERDUE_DEBT_RATIO'].fillna(0)\n",
    "application_bureau_test['OVERDUE_DEBT_RATIO'] = application_bureau_test.replace([np.inf, -np.inf], 0)\n",
    "application_bureau_test['OVERDUE_DEBT_RATIO'] = pd.to_numeric(application_bureau_test['OVERDUE_DEBT_RATIO'], downcast='float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of previous applications per customer\n",
    "grp = previous_application[['SK_ID_CURR','SK_ID_PREV']].groupby(by=['SK_ID_CURR'])['SK_ID_PREV'].count().reset_index().rename(columns={'SK_ID_PREV':'PREV_APP_COUNT'})\n",
    "\n",
    "# Take only the IDs which are present in application_bureau\n",
    "application_bureau_prev = application_bureau.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev_test = application_bureau_test.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "#Fill NA for previous application counts (lets say there was an application ID present in application_bureau but not present\n",
    "# in grp, then that means that person never took loan previously, so count of previous loan for that person = 0)\n",
    "application_bureau_prev['PREV_APP_COUNT'] = application_bureau_prev['PREV_APP_COUNT'].fillna(0)\n",
    "application_bureau_prev_test['PREV_APP_COUNT'] = application_bureau_prev_test['PREV_APP_COUNT'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining numerical features\n",
    "\n",
    "#Take the mean of all the parameters (grouping by SK_ID_CURR)\n",
    "grp = previous_application.drop('SK_ID_PREV', axis =1).groupby(by=['SK_ID_CURR']).mean().reset_index()\n",
    "\n",
    "#Add prefix prev in front of all columns so that we know that these columns are from previous_application\n",
    "prev_columns = ['PREV_'+column if column != 'SK_ID_CURR' else column for column in grp.columns ]\n",
    "\n",
    "#Change the columns\n",
    "grp.columns = prev_columns\n",
    "\n",
    "application_bureau_prev = application_bureau_prev.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev.update(application_bureau_prev[grp.columns].fillna(0))\n",
    "application_bureau_prev_test = application_bureau_prev_test.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev_test.update(application_bureau_prev_test[grp.columns].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining categorical features\n",
    "prev_categorical = pd.get_dummies(previous_application.select_dtypes('object'))\n",
    "prev_categorical['SK_ID_CURR'] = previous_application['SK_ID_CURR']\n",
    "\n",
    "grp = prev_categorical.groupby('SK_ID_CURR').mean().reset_index()\n",
    "grp.columns = ['PREV_'+column if column != 'SK_ID_CURR' else column for column in grp.columns]\n",
    "\n",
    "application_bureau_prev = application_bureau_prev.merge(grp, on=['SK_ID_CURR'], how='left')\n",
    "application_bureau_prev.update(application_bureau_prev[grp.columns].fillna(0))\n",
    "\n",
    "application_bureau_prev_test = application_bureau_prev_test.merge(grp, on=['SK_ID_CURR'], how='left')\n",
    "application_bureau_prev_test.update(application_bureau_prev_test[grp.columns].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining numerical features\n",
    "grp = pos_cash.drop('SK_ID_PREV', axis =1).groupby(by=['SK_ID_CURR']).mean().reset_index()\n",
    "prev_columns = ['POS_'+column if column != 'SK_ID_CURR' else column for column in grp.columns ]\n",
    "grp.columns = prev_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_bureau_prev = application_bureau_prev.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev.update(application_bureau_prev[grp.columns].fillna(0))\n",
    "\n",
    "application_bureau_prev_test = application_bureau_prev_test.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev_test.update(application_bureau_prev_test[grp.columns].fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining categorical features\n",
    "pos_cash_categorical = pd.get_dummies(pos_cash.select_dtypes('object'))\n",
    "pos_cash_categorical['SK_ID_CURR'] = pos_cash['SK_ID_CURR']\n",
    "\n",
    "grp = pos_cash_categorical.groupby('SK_ID_CURR').mean().reset_index()\n",
    "grp.columns = ['POS_'+column if column != 'SK_ID_CURR' else column for column in grp.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_bureau_prev = application_bureau_prev.merge(grp, on=['SK_ID_CURR'], how='left')\n",
    "application_bureau_prev.update(application_bureau_prev[grp.columns].fillna(0))\n",
    "\n",
    "application_bureau_prev_test = application_bureau_prev_test.merge(grp, on=['SK_ID_CURR'], how='left')\n",
    "application_bureau_prev_test.update(application_bureau_prev_test[grp.columns].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining numerical features and there are no categorical features in this dataset\n",
    "grp = install_payments.drop('SK_ID_PREV', axis =1).groupby(by=['SK_ID_CURR']).mean().reset_index()\n",
    "prev_columns = ['INSTALL_'+column if column != 'SK_ID_CURR' else column for column in grp.columns ]\n",
    "grp.columns = prev_columns\n",
    "application_bureau_prev = application_bureau_prev.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev.update(application_bureau_prev[grp.columns].fillna(0))\n",
    "application_bureau_prev_test = application_bureau_prev_test.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev_test.update(application_bureau_prev_test[grp.columns].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidharthjindal/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#last_loan_late_payment (mean and max)\n",
    "grp = install_payments[['SK_ID_CURR','DAYS_ENTRY_PAYMENT','DAYS_INSTALMENT']]\n",
    "\n",
    "grp['late_payment'] = grp['DAYS_ENTRY_PAYMENT'] - grp['DAYS_INSTALMENT']\n",
    "\n",
    "del(grp['DAYS_ENTRY_PAYMENT'])\n",
    "del(grp['DAYS_INSTALMENT'])\n",
    "\n",
    "grp2 = grp.groupby(by =['SK_ID_CURR']).mean().reset_index().rename(columns={'late_payment':'late_payment_mean'})\n",
    "grp3 = grp.groupby(by =['SK_ID_CURR']).max().reset_index().rename(columns={'late_payment':'late_payment_max'})\n",
    "\n",
    "application_bureau_prev = application_bureau_prev.merge(grp2, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev = application_bureau_prev.merge(grp3, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev.update(application_bureau_prev['late_payment_max'].fillna(0))\n",
    "application_bureau_prev.update(application_bureau_prev['late_payment_mean'].fillna(0))\n",
    "\n",
    "application_bureau_prev_test = application_bureau_prev_test.merge(grp2, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev_test = application_bureau_prev_test.merge(grp3, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev_test.update(application_bureau_prev_test['late_payment_max'].fillna(0))\n",
    "application_bureau_prev_test.update(application_bureau_prev_test['late_payment_mean'].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combining numerical features\n",
    "grp = credit_card.drop('SK_ID_PREV', axis =1).groupby(by=['SK_ID_CURR']).mean().reset_index()\n",
    "prev_columns = ['CREDIT_'+column if column != 'SK_ID_CURR' else column for column in grp.columns ]\n",
    "grp.columns = prev_columns\n",
    "application_bureau_prev = application_bureau_prev.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev.update(application_bureau_prev[grp.columns].fillna(0))\n",
    "\n",
    "application_bureau_prev_test = application_bureau_prev_test.merge(grp, on =['SK_ID_CURR'], how = 'left')\n",
    "application_bureau_prev_test.update(application_bureau_prev_test[grp.columns].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining categorical features\n",
    "credit_categorical = pd.get_dummies(credit_card.select_dtypes('object'))\n",
    "credit_categorical['SK_ID_CURR'] = credit_card['SK_ID_CURR']\n",
    "\n",
    "grp = credit_categorical.groupby('SK_ID_CURR').mean().reset_index()\n",
    "grp.columns = ['CREDIT_'+column if column != 'SK_ID_CURR' else column for column in grp.columns]\n",
    "\n",
    "application_bureau_prev = application_bureau_prev.merge(grp, on=['SK_ID_CURR'], how='left')\n",
    "application_bureau_prev.update(application_bureau_prev[grp.columns].fillna(0))\n",
    "\n",
    "application_bureau_prev_test = application_bureau_prev_test.merge(grp, on=['SK_ID_CURR'], how='left')\n",
    "application_bureau_prev_test.update(application_bureau_prev_test[grp.columns].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in application_bureau_prev:\n",
    "    if(\"/\" in col):\n",
    "        application_bureau_prev.rename(columns = {col : col[:col.find(\"/\")]}, inplace = True)\n",
    "    elif(\": \" in col):\n",
    "         application_bureau_prev.rename(columns = {col : col.replace(\": \",\"_\")}, inplace = True)\n",
    "    elif(\":\" in col):\n",
    "         application_bureau_prev.rename(columns = {col : col.replace(\":\",\"_\")}, inplace = True)\n",
    "            \n",
    "for col in application_bureau_prev_test:\n",
    "    if(\"/\" in col):\n",
    "        application_bureau_prev_test.rename(columns = {col : col[:col.find(\"/\")]}, inplace = True)\n",
    "    elif(\": \" in col):\n",
    "         application_bureau_prev_test.rename(columns = {col : col.replace(\": \",\"_\")}, inplace = True)\n",
    "    elif(\":\" in col):\n",
    "         application_bureau_prev_test.rename(columns = {col : col.replace(\":\",\"_\")}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', True)\n",
    "pd.set_option('display.max_rows', True)\n",
    "print(len(application_bureau_prev.columns))\n",
    "print(len(application_bureau_prev_test.columns))\n",
    "# for i in application_bureau_prev.columns:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import random\n",
    "# X=application_bureau_prev.drop(columns=['TARGET'], axis=1)\n",
    "# y=application_bureau_prev['TARGET']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 490)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                                 class_weight='balanced',\n",
       "                                                 criterion='gini', max_depth=20,\n",
       "                                                 max_features='sqrt',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 max_samples=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=5,\n",
       "                                                 min_samples_split=40,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=200, n_jobs=-1,\n",
       "                                                 oob_score=False,\n",
       "                                                 random_state=0, verbose=0,\n",
       "                                                 warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False,\n",
       "                threshold='6*median')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X=application_bureau_prev.dropna()\n",
    "X=application_bureau_prev.fillna(0)\n",
    "y=X['TARGET']\n",
    "X=X.drop(columns=['TARGET'], axis=1)\n",
    "print(X.shape)\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(random_state = 0, n_jobs=-1, class_weight=\"balanced\"\n",
    ",bootstrap= True,\n",
    " max_depth= 20,\n",
    " min_samples_leaf= 5,\n",
    " min_samples_split= 40,\n",
    " n_estimators= 200,\n",
    "max_features = 'sqrt')\n",
    "                                      \n",
    ", threshold='6*median')\n",
    "embeded_rf_selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SK_ID_CURR',\n",
       " 'CODE_GENDER',\n",
       " 'AMT_INCOME_TOTAL',\n",
       " 'AMT_CREDIT',\n",
       " 'AMT_ANNUITY',\n",
       " 'AMT_GOODS_PRICE',\n",
       " 'REGION_POPULATION_RELATIVE',\n",
       " 'DAYS_BIRTH',\n",
       " 'DAYS_EMPLOYED',\n",
       " 'DAYS_REGISTRATION',\n",
       " 'DAYS_ID_PUBLISH',\n",
       " 'HOUR_APPR_PROCESS_START',\n",
       " 'EXT_SOURCE_1',\n",
       " 'EXT_SOURCE_2',\n",
       " 'EXT_SOURCE_3',\n",
       " 'TOTALAREA_MODE',\n",
       " 'DAYS_LAST_PHONE_CHANGE',\n",
       " 'NAME_EDUCATION_TYPE_Higher education',\n",
       " 'Percent_Days_employed',\n",
       " 'Credit_as_percent_income',\n",
       " 'Annuity_as_percent_income',\n",
       " 'Credit_to_annuity',\n",
       " 'Credit_to_Goods',\n",
       " 'BUREAU_DAYS_CREDIT',\n",
       " 'BUREAU_DAYS_CREDIT_ENDDATE',\n",
       " 'BUREAU_DAYS_ENDDATE_FACT',\n",
       " 'BUREAU_AMT_CREDIT_MAX_OVERDUE',\n",
       " 'BUREAU_AMT_CREDIT_SUM',\n",
       " 'BUREAU_AMT_CREDIT_SUM_DEBT',\n",
       " 'BUREAU_DAYS_CREDIT_UPDATE',\n",
       " 'DAYS_ENDDATE_FACT_MAX',\n",
       " 'AmountCredit_OVER_MaxAmountCredited_Closed',\n",
       " 'AmountCredit_OVER_MaxAmountCredited_Active',\n",
       " 'Active_Credit_to_Income_Ratio',\n",
       " 'BUREAU_CREDIT_ACTIVE_Active',\n",
       " 'BUREAU_CREDIT_ACTIVE_Closed',\n",
       " 'BUREAU_LOAN_COUNT_ACTIVE',\n",
       " 'DEBT_CREDIT_RATIO',\n",
       " 'OVERDUE_DEBT_RATIO',\n",
       " 'PREV_AMT_ANNUITY',\n",
       " 'PREV_AMT_APPLICATION',\n",
       " 'PREV_AMT_CREDIT',\n",
       " 'PREV_AMT_DOWN_PAYMENT',\n",
       " 'PREV_AMT_GOODS_PRICE',\n",
       " 'PREV_HOUR_APPR_PROCESS_START',\n",
       " 'PREV_RATE_DOWN_PAYMENT',\n",
       " 'PREV_DAYS_DECISION',\n",
       " 'PREV_SELLERPLACE_AREA',\n",
       " 'PREV_CNT_PAYMENT',\n",
       " 'PREV_DAYS_FIRST_DUE',\n",
       " 'PREV_DAYS_LAST_DUE_1ST_VERSION',\n",
       " 'PREV_DAYS_LAST_DUE',\n",
       " 'PREV_DAYS_TERMINATION',\n",
       " 'PREV_NAME_CONTRACT_STATUS_Approved',\n",
       " 'PREV_NAME_CONTRACT_STATUS_Refused',\n",
       " 'PREV_CODE_REJECT_REASON_XAP',\n",
       " 'PREV_NAME_CLIENT_TYPE_New',\n",
       " 'PREV_NAME_PRODUCT_TYPE_walk-in',\n",
       " 'PREV_NAME_YIELD_GROUP_high',\n",
       " 'POS_MONTHS_BALANCE',\n",
       " 'POS_CNT_INSTALMENT',\n",
       " 'POS_CNT_INSTALMENT_FUTURE',\n",
       " 'POS_SK_DPD_DEF',\n",
       " 'POS_NAME_CONTRACT_STATUS_Active',\n",
       " 'POS_NAME_CONTRACT_STATUS_Completed',\n",
       " 'INSTALL_NUM_INSTALMENT_VERSION',\n",
       " 'INSTALL_NUM_INSTALMENT_NUMBER',\n",
       " 'INSTALL_DAYS_INSTALMENT',\n",
       " 'INSTALL_DAYS_ENTRY_PAYMENT',\n",
       " 'INSTALL_AMT_INSTALMENT',\n",
       " 'INSTALL_AMT_PAYMENT',\n",
       " 'late_payment_mean',\n",
       " 'late_payment_max',\n",
       " 'CREDIT_CNT_DRAWINGS_CURRENT']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imputation_train = application_bureau_prev[embeded_rf_feature]\n",
    "\n",
    "\n",
    "X_imputation_test = application_bureau_prev_test[embeded_rf_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(BayesianRidge())\n",
    "\n",
    "imputed_total_train = pd.DataFrame(imputer.fit_transform(X_imputation_train))\n",
    "imputed_total_train.columns = X_imputation_train.columns\n",
    "\n",
    "imputed_total_test = pd.DataFrame(imputer.fit_transform(X_imputation_test))\n",
    "imputed_total_test.columns = X_imputation_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training set: [0.89707694 0.89632087 0.8958562 ]\n",
      "Accuracy on Test set: [0.90156578 0.90590703 0.90346812]\n"
     ]
    }
   ],
   "source": [
    "# tweaking the hyper parameters-score 0.73789\n",
    "y=application_bureau_prev[['SK_ID_CURR','TARGET']]\n",
    "\n",
    "X = imputed_total_train.merge(y, on='SK_ID_CURR',how ='left')\n",
    "#all rows with all important columns and target\n",
    "\n",
    "y1=X['TARGET']\n",
    "X1=X[X_imputation_train.columns.drop('SK_ID_CURR')]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state = 0, n_jobs=-1, class_weight=\"balanced\"\n",
    ",bootstrap= True,\n",
    " max_depth= 20,\n",
    " min_samples_leaf= 5,\n",
    " min_samples_split= 40,\n",
    " n_estimators= 200,\n",
    "max_features = 'sqrt')\n",
    "rf_clf.fit(X_train, y_train)\n",
    "print('Accuracy on Training set:',cross_val_score(rf_clf, X_train, y_train, cv=3, scoring='accuracy'))\n",
    "print('Accuracy on Test set:',cross_val_score(rf_clf, X_test, y_test, cv=3, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "imputed_total_test[X_imputation_test.columns.drop(['SK_ID_CURR'])].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_clf.predict_proba(imputed_total_test[X_imputation_test.columns.drop(['SK_ID_CURR'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in predictions:\n",
    "    result.append(i[1])\n",
    "# predictions = [i if (i > j) else j for [i,j] in predictions]\n",
    "# np.unique(predictions,return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.01219221, 0.01754679, 0.0178011 , ..., 0.81951688, 0.83715112,\n",
       "        0.88035004]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(result,return_counts = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df=pd.DataFrame(data={\"SK_ID_CURR\":application_bureau_prev_test[\"SK_ID_CURR\"],\"TARGET\":result}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df[['SK_ID_CURR','TARGET']].to_csv(\"Result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
